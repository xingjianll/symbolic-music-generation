{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-19T17:34:21.624887Z",
     "start_time": "2025-07-19T17:34:21.598207Z"
    }
   },
   "source": [
    "from miditok.utils import get_bars_ticks, split_score_per_tracks\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from symusic import Score, Track\n",
    "import symusic\n",
    "from symusic.core import TrackTickList, NoteTickList, NoteTick\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def extract_melody(t: Track) -> Track:\n",
    "    melody = []\n",
    "    z: NoteTick\n",
    "    # notes: NoteTickList = t.notes.filter(lambda note: note.duration >= 240, inplace=True)\n",
    "    notes: NoteTickList = t.notes\n",
    "    notes.sort(key=lambda x: x.start, inplace=True)\n",
    "    z: NoteTick\n",
    "    concurrent = []\n",
    "    curr = None\n",
    "    while notes:\n",
    "        note = notes.pop(0)\n",
    "        concurrent.append(note)\n",
    "        if notes:\n",
    "            note2 = notes[0]\n",
    "            if note2.start > note.start:\n",
    "                # pop highest pitch\n",
    "                max = concurrent.pop()\n",
    "                while concurrent:\n",
    "                    a = concurrent.pop()\n",
    "                    if a.pitch > max.pitch:\n",
    "                        max = a\n",
    "                if curr is None or max.pitch > curr.pitch or max.start >= curr.end - 20:\n",
    "                    melody.append(max)\n",
    "                    curr = max\n",
    "\n",
    "    new_track = symusic.Track()\n",
    "    for note in melody:\n",
    "        new_track.notes.append(note)\n",
    "    return new_track\n",
    "\n",
    "\n",
    "def split_notes_into_bars(track: Track, score: Score) -> List[List[NoteTick]]:\n",
    "    \"\"\"\n",
    "    Split track notes into bars based on bar tick positions.\n",
    "\n",
    "    Args:\n",
    "        track: Input track to split\n",
    "        score: The full Score object (needed to compute barlines)\n",
    "\n",
    "    Returns:\n",
    "        List of lists, where each inner list contains notes for one bar\n",
    "    \"\"\"\n",
    "    # Get bar tick positions\n",
    "    bar_ticks = sorted(get_bars_ticks(score))\n",
    "    if not bar_ticks:\n",
    "        return []\n",
    "\n",
    "    notes = list(track.notes)\n",
    "    notes.sort(key=lambda x: x.start)\n",
    "\n",
    "    # Split notes into bars\n",
    "    bars = []\n",
    "    current_bar_notes = []\n",
    "    bar_idx = 0\n",
    "    tick_tolerance = 20\n",
    "\n",
    "    for note in notes:\n",
    "        if note.duration == 0:\n",
    "            continue\n",
    "\n",
    "       # Find which bar this note belongs to\n",
    "        # Check if note should be in the next bar (with tolerance for timing inaccuracies)\n",
    "        while (bar_idx < len(bar_ticks) - 1 and\n",
    "               note.start + tick_tolerance >= bar_ticks[bar_idx + 1]):\n",
    "            # Finish current bar and start new one\n",
    "            if current_bar_notes:\n",
    "                bars.append(current_bar_notes)\n",
    "                current_bar_notes = []\n",
    "            bar_idx += 1\n",
    "\n",
    "        current_bar_notes.append(note)\n",
    "\n",
    "    # Add the last bar\n",
    "    if current_bar_notes:\n",
    "        bars.append(current_bar_notes)\n",
    "\n",
    "    return bars\n",
    "\n",
    "\n",
    "def segment_melody_by_bars(track: Track, score: Score, min_bars_per_segment: int = 4, max_bars_per_segment: int = 16, similarity_threshold: float = 0.3) -> List[Track]:\n",
    "    \"\"\"\n",
    "    Segment melody by bars, ensuring splits only happen at bar boundaries.\n",
    "\n",
    "    Args:\n",
    "        track: Input track to segment\n",
    "        score: The full Score object (needed to compute barlines)\n",
    "        min_bars_per_segment: Minimum number of bars per segment\n",
    "        max_bars_per_segment: Maximum number of bars per segment\n",
    "        similarity_threshold: Threshold for musical similarity (0-1, lower = more segments)\n",
    "\n",
    "    Returns:\n",
    "        List of Track objects representing the segmented passages\n",
    "    \"\"\"\n",
    "    if not track.notes or len(track.notes) < 2:\n",
    "        return [track]\n",
    "\n",
    "    # Split notes into bars\n",
    "    bars = split_notes_into_bars(track, score)\n",
    "\n",
    "    if not bars:\n",
    "        return [track]\n",
    "\n",
    "    # Now segment bars using musical similarity\n",
    "    segments = []\n",
    "    current_segment_bars = [bars[0]]\n",
    "\n",
    "    for i in range(1, len(bars)):\n",
    "        current_bar = bars[i]\n",
    "        prev_bar = bars[i - 1]\n",
    "\n",
    "        if not current_bar or not prev_bar:\n",
    "            current_segment_bars.append(current_bar)\n",
    "            continue\n",
    "\n",
    "        # Calculate bar-level features\n",
    "        dissimilarity = calculate_bar_dissimilarity(prev_bar, current_bar)\n",
    "\n",
    "        current_segment_length = len(current_segment_bars)\n",
    "\n",
    "        should_split = (\n",
    "            dissimilarity > similarity_threshold or\n",
    "            (current_segment_length >= min_bars_per_segment and dissimilarity > similarity_threshold * 0.7) or\n",
    "            current_segment_length >= max_bars_per_segment\n",
    "        )\n",
    "\n",
    "        if should_split and current_segment_length >= min_bars_per_segment:\n",
    "            segments.append(current_segment_bars)\n",
    "            current_segment_bars = [current_bar]\n",
    "        else:\n",
    "            current_segment_bars.append(current_bar)\n",
    "\n",
    "    # Add the last segment\n",
    "    if current_segment_bars:\n",
    "        segments.append(current_segment_bars)\n",
    "\n",
    "    # Convert bar segments back to Track objects\n",
    "    track_segments = []\n",
    "    for segment_bars in segments:\n",
    "        new_track = symusic.Track()\n",
    "        new_track.program = track.program\n",
    "        new_track.is_drum = track.is_drum\n",
    "        new_track.name = track.name\n",
    "\n",
    "        # Add all notes from all bars in this segment\n",
    "        for bar_notes in segment_bars:\n",
    "            for note in bar_notes:\n",
    "                new_track.notes.append(note)\n",
    "\n",
    "        track_segments.append(new_track)\n",
    "\n",
    "    return track_segments\n",
    "\n",
    "\n",
    "def calculate_bar_dissimilarity(bar1_notes: List, bar2_notes: List) -> float:\n",
    "    \"\"\"\n",
    "    Calculate dissimilarity between two bars based on musical features.\n",
    "\n",
    "    Args:\n",
    "        bar1_notes: List of notes in the first bar\n",
    "        bar2_notes: List of notes in the second bar\n",
    "\n",
    "    Returns:\n",
    "        Dissimilarity score (0-1, higher = more dissimilar)\n",
    "    \"\"\"\n",
    "    if not bar1_notes or not bar2_notes:\n",
    "        return 1.0\n",
    "\n",
    "    # Feature 1: Average pitch difference\n",
    "    avg_pitch1 = np.mean([note.pitch for note in bar1_notes])\n",
    "    avg_pitch2 = np.mean([note.pitch for note in bar2_notes])\n",
    "    pitch_diff = abs(avg_pitch1 - avg_pitch2)\n",
    "    pitch_diff_norm = min(pitch_diff / 12, 1.0)  # Normalize by octave\n",
    "\n",
    "    # Feature 2: Note count difference\n",
    "    count_diff = abs(len(bar1_notes) - len(bar2_notes))\n",
    "    count_diff_norm = min(count_diff / max(len(bar1_notes), len(bar2_notes)), 1.0)\n",
    "\n",
    "    # Feature 3: Average duration difference\n",
    "    avg_dur1 = np.mean([note.duration for note in bar1_notes])\n",
    "    avg_dur2 = np.mean([note.duration for note in bar2_notes])\n",
    "    dur_ratio = max(avg_dur1, avg_dur2) / min(avg_dur1, avg_dur2)\n",
    "    dur_diff_norm = min((dur_ratio - 1) / 3, 1.0)  # Normalize duration ratio\n",
    "\n",
    "    # Feature 4: Pitch range difference\n",
    "    pitch_range1 = max(note.pitch for note in bar1_notes) - min(note.pitch for note in bar1_notes)\n",
    "    pitch_range2 = max(note.pitch for note in bar2_notes) - min(note.pitch for note in bar2_notes)\n",
    "    range_diff = abs(pitch_range1 - pitch_range2)\n",
    "    range_diff_norm = min(range_diff / 12, 1.0)\n",
    "\n",
    "    # Feature 5: Time gap between bars\n",
    "    bar1_end = max(note.end for note in bar1_notes)\n",
    "    bar2_start = min(note.start for note in bar2_notes)\n",
    "    time_gap = bar2_start - bar1_end\n",
    "    time_gap_norm = min(time_gap / 240, 1.0) if time_gap > 0 else 0\n",
    "\n",
    "    # Weighted combination\n",
    "    dissimilarity = (\n",
    "        pitch_diff_norm * 0.3 +\n",
    "        count_diff_norm * 0.2 +\n",
    "        dur_diff_norm * 0.2 +\n",
    "        range_diff_norm * 0.2 +\n",
    "        time_gap_norm * 0.1\n",
    "    )\n",
    "\n",
    "    return dissimilarity\n",
    "\n",
    "\n",
    "\n",
    "project_dir = Path(\"/Users/xingjianliu/repos/symbolic-music-generation\")\n",
    "data_dir = project_dir / \"data\"\n",
    "single_track_dir = data_dir / 'single_track'\n",
    "for file in os.listdir(single_track_dir):\n",
    "    score = Score(single_track_dir / file)\n",
    "    a: Track = score.tracks[0]\n",
    "    # score.tracks[0] = extract_melody(a)\n",
    "    # print(file)\n",
    "    # print(score)\n",
    "    tracks = segment_melody_by_bars(score.tracks[0], score, similarity_threshold=0.3, min_bars_per_segment=2, max_bars_per_segment=6)\n",
    "    # print(len(tracks))\n",
    "    for track in tracks:\n",
    "        score.tracks.append(track)\n",
    "\n",
    "    counter = 0\n",
    "    for score in split_score_per_tracks(score):\n",
    "        new_score = score.clip(score.tracks[0].notes[0].start, score.tracks[0].notes[-1].end).shift_time(-score.tracks[0].notes[0].start)\n",
    "        new_score.dump_midi(\"/Users/xingjianliu/repos/symbolic-music-generation/data/chunks/out\"+str(counter)+\".mid\")\n",
    "        counter += 1\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 247
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c3699ad953fb014a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
